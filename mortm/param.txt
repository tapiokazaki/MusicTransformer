n_layers (デフォルト: 6)

    意味: Transformerエンコーダのレイヤー数を指定します。
    役割: モデルの深さを決定します。より多くのレイヤーがあると、モデルはより複雑なパターンを学習できますが、計算コストも増加します。

num_heads (デフォルト: 8)

    意味: マルチヘッドアテンションのヘッド数を指定します。
    役割: アテンション機構におけるヘッドの数を決定します。複数のヘッドを使用することで、モデルは異なる部分に注意を向けることができます。

d_model (デフォルト: 512)

    意味: 各トークンの埋め込みベクトルの次元数を指定します。
    役割: モデルの表現力を決定します。より高い次元数は、より多くの情報を保持できますが、計算コストも増加します。
dim_feedforward (デフォルト: 1024)

    意味: フィードフォワードネットワークの隠れ層の次元数を指定します。
    役割: Transformerの各エンコーダレイヤー内のフィードフォワードネットワークのサイズを決定します。

dropout (デフォルト: 0.1)

    意味: ドロップアウト率を指定します。
    役割: ドロップアウトは、過学習を防ぐためにニューラルネットワークの一部のユニットをランダムに無効にする手法です。ドロップアウト率は、無効にするユニットの割合を指定します。

max_sequence (デフォルト: 2048)

    意味: モデルが処理できる最大シーケンス長を指定します。
    役割: モデルが一度に処理できるシーケンスの最大長を決定します。長いシーケンスに対しても対応できるように設定します。
rpr (デフォルト: False)

    意味: 相対位置表現（Relative Position Representations, RPR）を使用するかどうかを指定します。
    役割: RPRを使用する場合は、エンコーダ層をカスタムエンコーダに置き換え、位置エンコーディングの代わりに相対位置表現を使用します。RPRは、より効果的に位置情報をキャプチャできるとされています。

 Pipにアップロードするとき
 python .\setup.py sdist bdist_wheel
twine upload dist/*